{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLgYrU9LuTIcLkG7Fc/xQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrvarz123/ImageClassification/blob/main/L3%20Data%20Science_Household_Food_Wastage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0h_pbpyya8w"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "#-------------------------------------------------------------------------------\n",
        "# Read and Analyse Data\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Use raw string to handle backslashes properly\n",
        "file_path = r\"C:\\Users\\admin\\Python Programming\\WEEK_5\\global_food_wastage_dataset.csv\"\n",
        "\n",
        "\n",
        "output_folder = r\"C:\\python_workspace\\outputs\"\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "# Check if file exists\n",
        "if os.path.exists(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(df.head(10))\n",
        "    print(\"Data successfully loaded.\")\n",
        "\n",
        "#------------------------------------------------------------------------------#\n",
        "    df.head().to_csv(os.path.join(output_folder, \"data_head.csv\"), index=False)\n",
        "    df.describe().T.to_csv(os.path.join(output_folder, \"data_statistics.csv\"))\n",
        "#------------------------------------------------------------------------------#\n",
        "else:\n",
        "    print(f\"Error: The file '{file_path}' does not exist.\")\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Path to the local image\n",
        "image_path = r\"C:\\Users\\admin\\Python Programming\\WEEK_5\\hfcqdun.PNG\"\n",
        "\n",
        "# Open the image directly from the local file path\n",
        "img = Image.open(image_path)\n",
        "\n",
        "\n",
        "### Missing Value and Unique Counts Analysis\n",
        "# describe basic statistics of data\n",
        "df.describe().T\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "import missingno as msno\n",
        "msno.matrix(df)\n",
        "\n",
        "df[\"Country\"].value_counts()\n",
        "\n",
        "\n",
        "def func(df):\n",
        "    for column in df.columns :\n",
        "        print(f\"Unique counts for column: {column}\")\n",
        "        print(df[column].unique())\n",
        "        print()\n",
        "func(df)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "\n",
        "# URL of the shapefile\n",
        "#-------------------------------------------------------------------------------\n",
        "#url = 'https://www2.census.gov/geo/tiger/GENZ2022/shp/cb_2022_us_state_20m.zip'\n",
        "#url2 ='https://www.naturalearthdata.com/downloads/110m-cultural-vectors/' ## new version\n",
        "\n",
        "# Download the shapefile as a zip file\n",
        "#response = requests.get(url)\n",
        "#with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "#    zip_ref.extractall('path_to_extract_to')  # specify the folder where to extract\n",
        "\n",
        "# Read the shapefile\n",
        "#shapefile_path = 'path_to_extract_to/cb_2022_us_state_20m.shp'\n",
        "#world = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Check the data\n",
        "#print(world.head())\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the manually downloaded ZIP\n",
        "#zip_path = r'C:\\shapefiles_zip\\cb_2022_us_state_20m.zip'\n",
        "\n",
        "#zip_path = r'c:\\Users\\admin\\Downloads\\cb_2022_us_state_20m'  # or wherever it is\n",
        "\n",
        "zip_path = r'c:\\Users\\admin\\Downloads\\cb_2022_us_state_20m.zip'\n",
        "\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import geopandas as gpd\n",
        "\n",
        "# Path to the manually downloaded ZIP\n",
        "zip_path = r'c:\\Users\\admin\\Downloads\\cb_2022_us_state_20m.zip'\n",
        "extract_path = r'C:\\shapefiles'\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Read the shapefile\n",
        "shapefile_path = os.path.join(extract_path, 'cb_2022_us_state_20m.shp')\n",
        "world = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Show first few rows\n",
        "print(world.head())\n",
        "##------------------------------------------------------------------------------\n",
        "#\n",
        "##------------------------------------------------------------------------------\n",
        "from IPython.display import display\n",
        "\n",
        "display(world.head())\n",
        "#pip install tabulate\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Show as table in console\n",
        "print(tabulate(world.head(), headers='keys', tablefmt='fancy_grid'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "plt.figure(figsize=(14,8))\n",
        "sns.barplot(y=\"Country\", x=\"Total Waste (Tons)\", data=df, palette=\"magma\")\n",
        "plt.title(\"Total Food Waste by Country\", fontsize=16)\n",
        "plt.xlabel(\"Total Waste (Tons)\")\n",
        "plt.ylabel(\"Country\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(x=\"Year\", y=\"Total Waste (Tons)\", data=df, marker=\"o\",ci=None)\n",
        "plt.title(\"Total Food Waste Over the Years\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Total Waste (Tons)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=\"Year\", y=\"Economic Loss (Million $)\", data=df, marker=\"o\", color=\"darkblue\")\n",
        "\n",
        "plt.title(\"Economic Loss Over the Years\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Year\", fontsize=14)\n",
        "plt.ylabel(\"Economic Loss (Million $)\", fontsize=14)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))  # We adjusted the graphics size\n",
        "\n",
        "sns.lineplot(\n",
        "    x=\"Year\",\n",
        "    y=\"Household Waste (%)\",\n",
        "    data=df,\n",
        "    marker=\"o\",\n",
        "    color=\"green\",\n",
        "    linewidth=2,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "plt.title(\"Household Waste Percentage Over the Years\", fontsize=16, fontweight=\"bold\", color=\"darkgreen\")\n",
        "plt.xlabel(\"Year\", fontsize=14, fontweight=\"bold\", color=\"gray\")\n",
        "plt.ylabel(\"Household Waste (%)\", fontsize=14, fontweight=\"bold\", color=\"gray\")\n",
        "\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7, color=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df[\"Total Waste (Tons)\"], bins=30, kde=True, color=\"g\")\n",
        "plt.title(\"Distribution of Total Food Waste\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "\n",
        "\n",
        "sns.barplot(\n",
        "    y=\"Country\",\n",
        "    x=\"Household Waste (%)\",\n",
        "    data=df,\n",
        "    palette=\"magma\",\n",
        ")\n",
        "\n",
        "plt.title(\"Household Food Waste Percentage by Country\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Household Waste (%)\", fontsize=14)\n",
        "plt.ylabel(\"Country\", fontsize=14)\n",
        "\n",
        "# Show chart\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "\n",
        "sns.barplot(\n",
        "    y=\"Food Category\",\n",
        "    x=\"Total Waste (Tons)\",\n",
        "    data=df,\n",
        "    palette=\"rocket\",\n",
        ")\n",
        "\n",
        "# Title and tags\n",
        "plt.title(\"Total Waste by Food Category\", fontsize=16, fontweight=\"bold\", color=\"darkblue\")\n",
        "plt.xlabel(\"Total Waste (Tons)\", fontsize=14, fontweight=\"bold\", color=\"gray\")\n",
        "plt.ylabel(\"Food Category\", fontsize=14, fontweight=\"bold\", color=\"gray\")\n",
        "\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "### HeatMap\n",
        "#===============================================================================\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_encoded = df.copy()\n",
        "\n",
        "\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
        "    df_encoded[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_encoded.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "### Outlier Analysis\n",
        "#-------------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "def detect_outliers(df, method=\"IQR\", threshold=1.5):\n",
        "    outlier_dict = {}\n",
        "\n",
        "    for col in df.select_dtypes(include=[np.number]):\n",
        "        if method == \"IQR\":\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold * IQR\n",
        "            upper_bound = Q3 + threshold * IQR\n",
        "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "\n",
        "        elif method == \"z-score\":\n",
        "            mean = df[col].mean()\n",
        "            std = df[col].std()\n",
        "            z_scores = (df[col] - mean) / std\n",
        "            outliers = df[np.abs(z_scores) > threshold]\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid method! You should use 'IQR' or 'z-score'.\")\n",
        "\n",
        "        outlier_dict[col] = outliers[col].values\n",
        "\n",
        "        # Visualize outliers\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.boxplot(x=df[col])\n",
        "        plt.title(f\"Outliers ({col})\")\n",
        "        plt.show()\n",
        "\n",
        "    return outlier_dict\n",
        "\n",
        "outliers = detect_outliers(df, method=\"IQR\", threshold=1.5)\n",
        "\n",
        "for key, values in outliers.items():\n",
        "    print(f\"Outliers in the {key} column: {values}\")\n",
        "#-------------------------------------------------------------------------------\n",
        "from sklearn.preprocessing import StandardScaler  # to fix scale issues\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  # for rescaling\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def detect_outliers(df, method=\"IQR\", threshold=1.5, scale_data=True):\n",
        "    outlier_dict = {}\n",
        "\n",
        "    # Select only numeric columns\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    # Scale the data if needed\n",
        "    if scale_data:\n",
        "        scaler = StandardScaler()\n",
        "        df_scaled = pd.DataFrame(scaler.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
        "    else:\n",
        "        df_scaled = df[numeric_cols]\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if method == \"IQR\":\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold * IQR\n",
        "            upper_bound = Q3 + threshold * IQR\n",
        "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "\n",
        "        elif method == \"z-score\":\n",
        "            mean = df[col].mean()\n",
        "            std = df[col].std()\n",
        "            z_scores = (df[col] - mean) / std\n",
        "            outliers = df[np.abs(z_scores) > threshold]\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid method! Use 'IQR' or 'z-score'.\")\n",
        "\n",
        "        outlier_dict[col] = outliers[col].values\n",
        "\n",
        "    # Combined boxplot\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    sns.boxplot(data=df_scaled, orient=\"h\", color=\"lightblue\")  # <-- all dark blue\n",
        "    plt.title(\"Outliers Across All Numeric Columns (Scaled)\", fontsize=18)\n",
        "    plt.xlabel(\"Scaled Value\", fontsize=14)\n",
        "    plt.ylabel(\"Feature\", fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "    return outlier_dict\n",
        "\n",
        "# Example call\n",
        "outliers = detect_outliers(df, method=\"IQR\", threshold=1.5, scale_data=True)\n",
        "\n",
        "# Print detected outliers\n",
        "for key, values in outliers.items():\n",
        "    print(f\"Outliers in {key} column: {values}\")\n",
        "#-------------------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------\n",
        "#===============================================================================\n",
        "def create_outlier_table(df, method=\"IQR\", threshold=1.5):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    outlier_table = pd.DataFrame(False, index=df.index, columns=numeric_cols)  # initially False\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if method == \"IQR\":\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold * IQR\n",
        "            upper_bound = Q3 + threshold * IQR\n",
        "            outlier_condition = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
        "\n",
        "        elif method == \"z-score\":\n",
        "            mean = df[col].mean()\n",
        "            std = df[col].std()\n",
        "            z_scores = (df[col] - mean) / std\n",
        "            outlier_condition = (np.abs(z_scores) > threshold)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid method! Use 'IQR' or 'z-score'.\")\n",
        "\n",
        "        # Mark True if it's an outlier\n",
        "        outlier_table[col] = outlier_condition\n",
        "\n",
        "    return outlier_table\n",
        "\n",
        "# Create the outlier table\n",
        "outlier_table = create_outlier_table(df, method=\"IQR\", threshold=1.5)\n",
        "\n",
        "# View it\n",
        "outlier_table.head(10)  # Show first 10 rows\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# STEP 1: Create the outlier table\n",
        "#outlier_table = create_outlier_table(df, method=\"IQR\", threshold=1.5)\n",
        "\n",
        "# STEP 2: Check if ANY outliers exist at all\n",
        "#if outlier_table.any().any():\n",
        "#    print(\"Outliers detected! Showing first few rows where outliers exist:\")\n",
        "\n",
        "    # Show only rows where there is at least one outlier\n",
        "#    df_outliers_only = df[outlier_table.any(axis=1)]\n",
        "#    print(df_outliers_only)\n",
        "#else:\n",
        "#    print(\"No strong outliers detected based on current method and threshold.\")\n",
        "\n",
        "#outlier_table = create_outlier_table(df, method=\"IQR\", threshold=1.0)\n",
        "\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# ML Modelling , Tuning and Evaluation\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "X = df.drop('Total Waste (Tons)', axis=1)\n",
        "y = df['Total Waste (Tons)']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# One Hot Encoding\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "# Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "xg_model = xgb.XGBRegressor(random_state=42)\n",
        "xg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Making predictions with test data of XGBoost model\n",
        "y_pred_xg = xg_model.predict(X_test_scaled)\n",
        "\n",
        "# MSE ve R² calculations\n",
        "#mse_xg = mean_squared_error(y_test, y_pred_xg)\n",
        "#r2_xg = r2_score(y_test, y_pred_xg)\n",
        "\n",
        "#print(f\"XGBoost MSE: {mse_xg}\")\n",
        "#print(f\"XGBoost R²: {r2_xg}\")\n",
        "\n",
        "#rf_model = RandomForestRegressor(random_state=42)\n",
        "#rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "#y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "#mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "#r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "#print(f\"Random Forest MSE: {mse_rf}\")\n",
        "#print(f\"Random Forest R²: {r2_rf}\")\n",
        "\n",
        "\n",
        "#rf_model = RandomForestRegressor(random_state=42)\n",
        "#rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "#y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "#mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "#r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "#print(f\"Random Forest MSE: {mse_rf}\")\n",
        "#print(f\"Random Forest R²: {r2_rf}\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#metrics_file = os.path.join(output_folder, \"model_metrics.txt\")\n",
        "#with open(metrics_file, \"w\") as f:\n",
        "#    f.write(f\"XGBoost MSE: {mse_xg}\\n\")\n",
        "#    f.write(f\"XGBoost R²: {r2_xg}\\n\")\n",
        "#    f.write(f\"Random Forest MSE: {mse_rf}\\n\")\n",
        "#    f.write(f\"Random Forest R²: {r2_rf}\\n\")\n",
        "#-------------------------------------------------------------------------------\n",
        "#plt.savefig(os.path.join(output_folder, \"total_food_waste_by_country.png\"))\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- XGBoost Predictions ---\n",
        "mse_xg = mean_squared_error(y_test, y_pred_xg)\n",
        "r2_xg = r2_score(y_test, y_pred_xg)\n",
        "print(f\"XGBoost MSE: {mse_xg}\")\n",
        "print(f\"XGBoost R²: {r2_xg}\")\n",
        "\n",
        "# --- Random Forest Model ---\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest MSE: {mse_rf}\")\n",
        "print(f\"Random Forest R²: {r2_rf}\")\n",
        "\n",
        "# --- Save Metrics to File ---\n",
        "metrics_file = os.path.join(output_folder, \"model_metrics.txt\")\n",
        "with open(metrics_file, \"w\") as f:\n",
        "    f.write(f\"XGBoost MSE: {mse_xg}\\n\")\n",
        "    f.write(f\"XGBoost R²: {r2_xg}\\n\")\n",
        "    f.write(f\"Random Forest MSE: {mse_rf}\\n\")\n",
        "    f.write(f\"Random Forest R²: {r2_rf}\\n\")\n",
        "\n",
        "#---- Save Plot (if one was created before) ------------------------------------\n",
        "plt.savefig(os.path.join(output_folder, \"total_food_waste_by_country.png\"))\n",
        "################################################################################\n",
        "################################################################################\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Model names and corresponding metrics\n",
        "models = ['XGBoost', 'Random Forest']\n",
        "mse_values = [mse_xg, mse_rf]\n",
        "r2_values = [r2_xg, r2_rf]\n",
        "\n",
        "x = np.arange(len(models))  # label locations\n",
        "width = 0.35  # width of the bars\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "ax2 = ax1.twinx()  # Create a second y-axis for R²\n",
        "\n",
        "# Plot MSE on the left y-axis\n",
        "bar1 = ax1.bar(x - width/2, mse_values, width, label='MSE', color='red')\n",
        "ax1.set_ylabel('Mean Squared Error')\n",
        "ax1.set_ylim(0, max(mse_values) * 1.1)\n",
        "\n",
        "# Plot R² on the right y-axis\n",
        "bar2 = ax2.bar(x + width/2, r2_values, width, label='R² Score', color='green')\n",
        "ax2.set_ylabel('R² Score')\n",
        "ax2.set_ylim(0, 1.05)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Model Performance Comparison')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bar1:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height * 1.01, f'{height:,.0f}', ha='center', va='bottom')\n",
        "\n",
        "for bar in bar2:\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Create a combined legend\n",
        "bars = bar1 + bar2\n",
        "labels = [bar.get_label() for bar in bars]\n",
        "ax1.legend(bars, ['MSE', 'R² Score'], loc='upper center')\n",
        "\n",
        "# Save and show\n",
        "plot_path = os.path.join(output_folder, 'model_comparison_metrics.png')\n",
        "plt.tight_layout()\n",
        "plt.savefig(plot_path)\n",
        "plt.show()\n",
        "\n",
        "#===============================================================================\n",
        "#===============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Example data (use your own mse_xg, mse_rf, r2_xg, r2_rf)\n",
        "mse_xg, mse_rf = 10217, 9528\n",
        "r2_xg, r2_rf = 0.953, 0.956\n",
        "\n",
        "# Model names and corresponding metrics\n",
        "models = ['XGBoost', 'Random Forest']\n",
        "mse_values = [mse_xg, mse_rf]\n",
        "r2_values = [r2_xg, r2_rf]\n",
        "\n",
        "x = np.arange(len(models))  # label locations\n",
        "width = 0.35  # width of the bars\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "ax2 = ax1.twinx()  # Create a second y-axis for R²\n",
        "\n",
        "# Plot MSE on the left y-axis\n",
        "bar1 = ax1.bar(x - width/2, mse_values, width, label='MSE', color='orange')\n",
        "ax1.set_ylabel('Mean Squared Error')\n",
        "ax1.set_ylim(0, max(mse_values) * 1.1)\n",
        "\n",
        "# Plot R² on the right y-axis\n",
        "bar2 = ax2.bar(x + width/2, r2_values, width, label='R² Score', color='lightgray')\n",
        "ax2.set_ylabel('R² Score')\n",
        "ax2.set_ylim(0, 1.05)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Model Performance Comparison')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bar1:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height * 1.01, f'{height:,.0f}', ha='center', va='bottom')\n",
        "\n",
        "for bar in bar2:\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Create a CLEANER combined legend for each model separately\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "legend_elements = [\n",
        "    Patch(facecolor='orange', label='MSE (XGBoost & RF)'),\n",
        "    Patch(facecolor='lightgray', label='R² Score (XGBoost & RF)')\n",
        "]\n",
        "\n",
        "ax1.legend(handles=legend_elements, loc='upper center')\n",
        "\n",
        "# Save and show\n",
        "output_folder = \".\"  # example\n",
        "plot_path = os.path.join(output_folder, 'model_comparison_metrics.png')\n",
        "plt.tight_layout()\n",
        "plt.savefig(plot_path)\n",
        "plt.show()\n"
      ]
    }
  ]
}